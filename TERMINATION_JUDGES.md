# Jueces de Terminaci√≥n del Entrenamiento Federado

Este documento explica los dos jueces (judges) que controlan cu√°ndo termina el entrenamiento federado distribuido.

## üìä Resumen

El sistema implementa **dos condiciones de terminaci√≥n independientes** para detener el entrenamiento cuando:
1. **Juez 1 (Early Stopping)**: El recall global no mejora durante muchos rounds
2. **Juez 2 (Max Rounds)**: Se alcanza un l√≠mite m√°ximo de rounds

Cualquiera de los dos puede terminar el entrenamiento. El agregador notifica a todos los agentes via polling y todo el sistema se detiene de manera coordinada.

---

## üéØ Juez 1: Early Stopping por Recall Global

### Concepto
Termina el entrenamiento si el **recall global** no mejora significativamente durante un per√≠odo prolongado (paciencia).

### Par√°metros (en `config_aggregator.json`)
```json
{
  "early_stopping_patience": 120,
  "early_stopping_min_delta": 0.0001
}
```

- **`early_stopping_patience`**: N√∫mero de rounds sin mejora antes de terminar (default: 120)
- **`early_stopping_min_delta`**: Mejora m√≠nima para considerar que hubo progreso (default: 0.0001)

### Funcionamiento

#### 1. Los agentes env√≠an recall local
Despu√©s de cada round de entrenamiento, cada agente:
```python
# En classification_engine.py
accuracy = compute_performance(models, prep_test_data(), True)
fl_client.send_recall_metric(accuracy)  # ‚Üê Env√≠a recall al agregador
```

#### 2. El agregador calcula recall global
El agregador espera hasta recibir recall de **TODOS** los agentes registrados:
```python
# En server_th.py: _process_recall_upload()
if len(self.current_round_recalls) >= num_agents:
    # Promedio de todos los recalls
    global_recall = sum(self.current_round_recalls.values()) / len(self.current_round_recalls)
```

#### 3. El agregador verifica mejora
```python
if global_recall > self.best_global_recall + self.early_stopping_min_delta:
    # ‚úì Hubo mejora
    self.best_global_recall = global_recall
    self.rounds_without_improvement = 0
else:
    # ‚úó No hubo mejora
    self.rounds_without_improvement += 1
```

#### 4. Terminaci√≥n si se agota la paciencia
```python
if self.rounds_without_improvement >= self.early_stopping_patience:
    # üõë TERMINAR: No mejora en 120 rounds
    self.pending_termination_msg = generate_termination_msg(
        reason=f"No improvement for {self.early_stopping_patience} rounds",
        final_round=self.sm.round,
        final_recall=self.best_global_recall
    )
```

### Ejemplo
```
Round 1: Recall=0.65 ‚Üí best=0.65, sin_mejora=0
Round 2: Recall=0.67 ‚Üí best=0.67, sin_mejora=0  (mejor√≥ +0.02)
Round 3: Recall=0.66 ‚Üí best=0.67, sin_mejora=1  (no mejor√≥)
Round 4: Recall=0.66 ‚Üí best=0.67, sin_mejora=2
...
Round 122: Recall=0.67 ‚Üí best=0.67, sin_mejora=120
üõë TRAINING TERMINATED: Early stopping triggered
```

---

## üî¢ Juez 2: L√≠mite M√°ximo de Rounds

### Concepto
Termina el entrenamiento si se alcanza un n√∫mero m√°ximo de rounds, independientemente del rendimiento.

### Par√°metros (en `config_aggregator.json`)
```json
{
  "max_rounds": 100
}
```

- **`max_rounds`**: N√∫mero m√°ximo de rounds de entrenamiento (default: 100)

### Funcionamiento

El agregador verifica en cada round:
```python
# En server_th.py: _check_termination_judges()
if self.sm.round >= self.max_rounds:
    # üõë TERMINAR: Alcanz√≥ el l√≠mite
    self.pending_termination_msg = generate_termination_msg(
        reason=f"Reached maximum rounds limit ({self.max_rounds})",
        final_round=self.sm.round,
        final_recall=self.best_global_recall
    )
```

### Ejemplo
```
Round 98: Agregaci√≥n OK
Round 99: Agregaci√≥n OK
Round 100: Agregaci√≥n OK
üõë TRAINING TERMINATED: Reached max rounds (100)
```

---

## üîÑ Flujo de Terminaci√≥n

### 1. Detecci√≥n de Condici√≥n de Terminaci√≥n
```
Agregador (server_th.py)
  ‚Üì
_check_termination_judges()
  ‚Üì
[Juez 1: rounds_without_improvement >= 120?]
[Juez 2: sm.round >= 100?]
  ‚Üì
Si alguno es True:
  ‚Üí self.training_terminated = True
  ‚Üí self.pending_termination_msg = generate_termination_msg(...)
```

### 2. Notificaci√≥n a Agentes via Polling
```
Agente hace polling ‚Üí Client.process_polling()
  ‚Üì
Agregador responde ‚Üí _process_polling()
  ‚Üì
if self.pending_termination_msg is not None:
  ‚Üí Env√≠a AggMsgType.termination
```

### 3. Agente Recibe y Termina
```python
# En client.py: process_polling()
if msg_type == AggMsgType.termination:
    reason = resp[TerminationMsgLocation.reason]
    final_round = resp[TerminationMsgLocation.final_round]
    final_recall = resp[TerminationMsgLocation.final_recall]
    
    logging.warning(f'üõë TRAINING TERMINATED by aggregator')
    logging.info(f'Reason: {reason}')
    logging.info(f'Final round: {final_round}')
    logging.info(f'Final global recall: {final_recall:.4f}')
    
    os._exit(0)  # ‚Üê Salida limpia
```

---

## üìù Logs Esperados

### En el Agregador
```
INFO:root:--- Recall Upload Received: agent=abc123, recall=0.6543, round=45 ---
INFO:root:=== GLOBAL RECALL (Round 45): 0.6512 ===
INFO:root:Individual recalls: {'abc123': 0.6543, 'def456': 0.6480}
INFO:root:‚úì Global recall improved by 0.0023 (new best: 0.6512)
```

```
INFO:root:‚úó No improvement for 118 rounds (best: 0.6789)
INFO:root:‚úó No improvement for 119 rounds (best: 0.6789)
INFO:root:‚úó No improvement for 120 rounds (best: 0.6789)
WARNING:root:üõë TRAINING TERMINATED: Early stopping triggered
INFO:root:No improvement for 120 rounds
INFO:root:Best global recall: 0.6789
```

### En los Agentes
```
INFO:root:--- Recall metric (0.6543) sent to aggregator ---
INFO:root:--- Polling to see if there is any update ---
WARNING:root:üõë TRAINING TERMINATED by aggregator
INFO:root:Reason: No improvement for 120 rounds (patience exhausted)
INFO:root:Final round: 145
INFO:root:Final global recall: 0.6789
INFO:root:Agent exiting due to training termination...
```

---

## ‚öôÔ∏è Configuraci√≥n Recomendada

### Para Testing R√°pido
```json
{
  "max_rounds": 10,
  "early_stopping_patience": 5,
  "early_stopping_min_delta": 0.01
}
```
Termina en ~10 rounds o si no mejora en 5 rounds.

### Para Entrenamiento Real (CIFAR-10)
```json
{
  "max_rounds": 100,
  "early_stopping_patience": 120,
  "early_stopping_min_delta": 0.0001
}
```
Permite hasta 100 rounds, pero termina antes si no mejora en 120 rounds.

### Para Entrenamiento Largo
```json
{
  "max_rounds": 500,
  "early_stopping_patience": 50,
  "early_stopping_min_delta": 0.0005
}
```
M√°s rounds permitidos, pero paciencia m√°s estricta.

---

## üîß Integraci√≥n con Rotaci√≥n

Los jueces de terminaci√≥n son **independientes de la rotaci√≥n**:

- **Rotaci√≥n**: Cambia el agregador cada N rounds (controlado por `rotation_min_rounds` y `rotation_interval`)
- **Terminaci√≥n**: Detiene TODO el entrenamiento cuando se cumple la condici√≥n

**Cronolog√≠a t√≠pica:**
```
Round 0-1: Entrenamiento normal
Round 2: ROTACI√ìN (nuevo agregador elegido, todos reinician)
Round 3-4: Entrenamiento normal
Round 5: ROTACI√ìN
...
Round 97: Entrenamiento normal
Round 98: ‚úó No mejora (rounds_without_improvement=118)
Round 99: ‚úó No mejora (rounds_without_improvement=119)
Round 100: ‚úó No mejora (rounds_without_improvement=120)
üõë TERMINACI√ìN: Early stopping triggered
```

El nuevo agregador despu√©s de rotaci√≥n **hereda el estado de terminaci√≥n** (best_global_recall, rounds_without_improvement) desde la base de datos, asegurando continuidad en el seguimiento del progreso.

---

## üöÄ C√≥mo Usar

### 1. Configurar par√°metros
Edita `setups/config_aggregator.json` o usa el script:
```bash
./setup_device_config.sh r2
# Genera config con valores por defecto
```

### 2. Iniciar sistema
```bash
# En r2 (agregador inicial)
python -m fl_main.aggregator.role_supervisor 1 8765 a_aggregator

# En r1 y r3 (agentes)
python -m fl_main.agent.role_supervisor 1 50002 a2
python -m fl_main.agent.role_supervisor 1 50003 a3
```

### 3. Observar logs
Los logs mostrar√°n:
- Recall de cada agente
- Recall global promedio
- Contador de rounds sin mejora
- Mensaje de terminaci√≥n cuando se cumpla condici√≥n

### 4. Sistema termina autom√°ticamente
Todos los procesos (agregador y agentes) se detienen limpiamente cuando cualquier juez dispara terminaci√≥n.

---

## üìä Ventajas del Sistema Dual

1. **Eficiencia**: Early stopping evita entrenamiento innecesario
2. **Seguridad**: Max rounds previene ejecuci√≥n infinita
3. **Flexibilidad**: Ajusta par√°metros seg√∫n necesidades
4. **Coordinaci√≥n**: Todos los nodos terminan simult√°neamente
5. **Informaci√≥n**: Logs detallados de por qu√© termin√≥

---

## üêõ Troubleshooting

**Problema**: "No se recibe recall de los agentes"
- **Causa**: Los agentes no est√°n llamando `send_recall_metric()`
- **Soluci√≥n**: Verifica que `classification_engine.py` incluya:
  ```python
  fl_client.send_recall_metric(accuracy)
  ```

**Problema**: "Early stopping nunca se dispara"
- **Causa**: Recall sigue mejorando o `early_stopping_patience` es muy alto
- **Soluci√≥n**: Reduce `early_stopping_patience` o ajusta `early_stopping_min_delta`

**Problema**: "Terminaci√≥n no llega a todos los agentes"
- **Causa**: Agentes no est√°n haciendo polling activamente
- **Soluci√≥n**: Verifica que los agentes est√©n en estado `waiting_gm` y haciendo polling peri√≥dico

**Problema**: "Sistema contin√∫a despu√©s de terminaci√≥n"
- **Causa**: `pending_termination_msg` no se est√° enviando
- **Soluci√≥n**: Verifica prioridad en `_process_polling()` (termination debe ser Priority 0)
